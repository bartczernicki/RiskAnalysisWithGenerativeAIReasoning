| **Row #** | **Title** | **2023 Risk Factor Summary** | **2024 Risk Factor Summary** | **Change** |
|---|---|---|---|---|
| 1 | Cyberattacks and security vulnerabilities | Emphasizes that cyberattacks or security issues can harm revenue, increase costs, create liabilities, and damage reputation or market position. Notes the continuous nature of threats from sophisticated actors, including nation-states, and warns of the evolving challenge posed by malware, phishing, etc. | Maintains the overall warning that cyberattacks can reduce revenue, increase costs, and harm reputation. More explicitly references that Microsoft has already experienced cybersecurity incidents by sophisticated nation-state actors. Highlights how threat actors have gained unauthorized access to Microsoft systems and data, pointing to real-life examples like the legacy test account compromise. | Expanded detail on actual security breaches and explicit references to active threat actors. Addresses ongoing or future impacts of known breaches, making the discussion more concrete and urgent. |
| 2 | Security of our information technology | Stresses various forms of IT security threats, including social engineering, supply chain attacks, and state-sponsored aggression. Mentions that evolving threats require continuous vigilance and places responsibility on internal security controls against new technologies like generative AI. | Broadly reiterates the same forms of threats and references specific breaches of Microsoft IT systems. Emphasizes the challenge of investigating sophisticated intrusions and the potential for large-scale, cascading effects. Notes that inadequate security practices by Microsoft or acquisitions/partners can lead to unauthorized access. | Refined to include more detail on past incidents, new references to AI-driven attacks, and real examples of successful breaches. Security challenges are portrayed as more persistent, with greater emphasis on the difficulty of quick detection and remediation. |
| 3 | Security of products, services, devices, and customers’ data | Focuses on the importance of product and service security to maintain trust. Warns of zero-day vulnerabilities, the tendency of adversaries to target popular services, and the ongoing need for robust updates. Mentions cloud reliance and customers’ varying technical capabilities. | Largely the same focus—product security and zero-day vulnerabilities—while stressing that compromises to Microsoft’s own systems also impact customers. Highlights that adversaries can exploit cloud services as well, and reaffirms the risk of open source and generative AI vulnerabilities. Draws attention to underprepared or less technically savvy customers. | Language updates to reflect recent real attacks on Microsoft products that also affected customers. Expanded discussion on generative AI as an emerging vector and clarifies how ongoing transformation and complex IT environments expose both Microsoft and its customers to heightened risk. |
| 4 | Development and deployment of defensive measures | Describes a continuing need for engineering more secure products, enhancing threat detection, and tightening deployment of patches. Notes the cost implications for such measures and the potential for reputation damage if vulnerabilities persist or patches are not installed. | Reiterates the commitment to strong security across internal systems and cloud offerings. Emphasizes timely deployment of defenses—both in Microsoft’s own environments and for customer updates—to mitigate advanced threats. Highlights specialized security demands from certain industries. | Stresses timely and more proactive security patching. Acknowledges higher customer expectations post-breach and clarifies Microsoft’s responsibility for mitigating newly emerging threats. Includes more explicit caution that inadequate security measures can trigger reputational or legal consequences. |
| 5 | Disclosure and misuse of personal data | Warns that storing large volumes of personal data exposes Microsoft to hostile external environments, risk of unauthorized access by employees or vendors, and potential legal liability and reputational harm. Mentions the possibility of government data requests. | Maintains warnings about large-scale personal data storage and breach risks. Adds greater emphasis on insider threats, clarifying that malicious or negligent insiders can misuse customer or user data. Restates that poor public perception about data protection can dampen sales or cloud adoption. | Refined to add explicit mention of insider misuse and the possibility of failing to detect such activity. Increasingly highlights the risk of new data privacy laws and the public’s escalating concerns, reflecting a broader regulatory environment. |
| 6 | Protecting information from unauthorized use | Focuses on contractual and technical measures to safeguard valuable data in LinkedIn and other platforms. Notes that legal changes may weaken Microsoft’s ability to prevent unauthorized third-party scraping or data gathering. | Restates the importance of protecting valuable platform-based data. Warns that changing legal interpretations can shift or weaken Microsoft’s legal protections against unauthorized data collection. Notes potential impacts on the business, financial condition, and operations. | Substantially similar emphasis. The 2024 version underscores how evolving legal standards may complicate enforcement against scraping, expanding on the potential business and operational risks. |
| 7 | Abuse of our platforms | Commends the need to prevent hostile or inappropriate content in services like GitHub, LinkedIn, Microsoft Advertising, Bing, and Xbox. Warns that flagging or removing such content requires substantial investments, which may not always succeed. | Continues warnings about hostile or misleading content, especially involving AI-generated impersonations or manipulative information. Adds detail on escalating regulatory scrutiny regarding content moderation. Notes heightened liability or reputational risk for failing to comply with evolving regulations and laws. | Expanded reference to AI-driven impersonation and manipulation. Greater stress on the potential for heightened regulatory oversight (e.g., content moderation obligations). Clarifies that failing to detect or remove content can result in more severe legal or reputational outcomes. |
| 8 | IoT and product usage risks | (2023) Emphasizes IoT vulnerabilities due to multiple hardware and software layers, limited patching ability, and significant security/privacy risks. Mentions that data collection in IoT contexts may not meet customer or regulatory requirements and could harm personal safety if solutions fail. | (2024) Broadens this to all products, services, and their interactions with third-party components—addressing IoT more generally. Acknowledges potential for high-risk environment misuses (including AI misuse). Stresses that failures in design or deployment (e.g., limited patching or misuse of data) may lead to legal enforcement. | The heading shifts from a specific focus on IoT to a broader lens on overall product usage, third-party interactions, and AI factors. The underlying themes remain—security, privacy, and operational risk—but with expanded application and more explicit coverage of AI and other technologies. |
| 9 | Issues in AI development and use | Highlights the incorporation of AI into products and acknowledges risks around flawed algorithms, data bias, or harmful content. Warns that controversies around AI’s societal impacts or privacy issues could harm Microsoft’s reputation. | Expands mention of AI’s growth, including Microsoft and OpenAI collaborations. Details legal and regulatory scrutiny (copyright claims, new AI legislation) and acknowledges that offensive or inaccurate AI outputs pose liability, brand, and competitive risks. References newly proposed U.S. and EU AI regulations. | Broadened to include concrete regulatory developments and real-world legal actions. Emphasizes a wider array of potential harms—ethical, legal, intellectual property—and the possibility of direct liability from AI training or outputs. More prominent mention of brand and reputational consequences.