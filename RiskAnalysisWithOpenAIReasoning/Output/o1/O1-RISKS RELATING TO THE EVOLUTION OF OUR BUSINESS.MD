| # | Title | 2023 Risk Factor Summary | 2024 Risk Factor Summary | Change |
|---|-------|-------------------------|-------------------------|--------|
| 1 | Cyberattacks and Security Vulnerabilities | Emphasizes that cyberattacks and continual security threats can cause serious harm to operations, reputation, and revenue. Mentions potential attacks from state-sponsored organizations. | Reinforces the same broad threat of cyberattacks leading to revenue and reputation harm, highlighting actual incidents of unauthorized access to systems. Stresses potential for sophisticated, long-term attacks. | **Modified**: More emphasis on actual attacks having occurred and the potential long-term impacts on reputation and operations. |
| 2 | Security of Our Information Technology | Discusses the myriad forms of security threats, including social engineering, ransomware, and nation-state attacks, especially in times of geopolitical tension (e.g., conflict in Ukraine). Warns of possible malicious actors exploiting vulnerabilities in hardware, software, or compromised supplier accounts. | Includes the same broad list of threats but explicitly references new cybersecurity incidents in late 2023. Adds detail on how unauthorized access to source code and internal systems occurred, posing significant risks. Underlines difficulties in fully investigating and remediating attacks. | **Modified**: Expanded to note a specific, detailed incident involving unauthorized access, and underscores complexities of remediation and detection. |
| 3 | Security of Our Products, Services, Devices, and Customers’ Data | Stresses threats to Microsoft products and services, highlighting that vulnerabilities persist if customers fail to apply patches, and that adversaries often target popular platforms. Notes zero-day attacks and the use of open source software. | Similar emphasis on vulnerabilities in products and services. References that threats to Microsoft’s own infrastructure (e.g., nation-state attack) also affect customers. Highlights generative AI as a new vector for attacks, and notes complexities in timely patching. | **Modified**: Retains the same core concern but emphasizes direct impacts from actual incidents, plus the evolving generative AI threat landscape. |
| 4 | Development and Deployment of Defensive Measures | Notes Microsoft’s need to continuously enhance security, threat detection, reliability features, and the deployment of patches. Warns that failing to do so or delayed adoption by customers could result in reputational or financial harm. | Reiterates continuous improvement and patch deployment needs. Adds urgency and the possibility that customers in specific sectors (e.g., government or financial services) have more stringent security expectations. Also highlights the potential for increased costs. | **Modified**: Core theme remains, but there is sharper focus on compliance and timeliness of defensive measures, especially in high-risk or regulated sectors. |
| 5 | Disclosure and Misuse of Personal Data | Explains the increase in personal data processing through cloud-based offerings. Warns that high-profile data breaches underscore a hostile environment, and that disclosure or misuse could harm reputation and lead to legal exposure. | Maintains that the growth of cloud offerings increases personal data stored. Adds the concept of potential insider threats and notes that third parties with limited access may misuse data. Mentions that stricter data laws could heighten costs or liability. | **Modified**: Enhanced emphasis on insider risks and third-party misuse in addition to more detailed references to regulatory pressures. |
| 6 | Protecting Information from Scraping or Unauthorized Use | Reflects concerns that valuable content (e.g., LinkedIn data) may be scraped or used without authorization by external parties, weakening Microsoft’s competitive advantages. | Continues to highlight the risk of unauthorized data scraping and references potential legal or interpretative changes that might make it harder to stop such activity. | **Modified**: Mostly the same risk, but further underscores how changes in law or legal interpretations could weaken protections. |
| 7 | Abuse of Our Platforms (Advertising, Professional, Marketplace, and Gaming) | Notes that platform abuses—misleading information, impersonation, or hostile content—can damage reputation or user engagement. Describes the difficulty of moderating such behavior. | Restates the same issues, emphasizing that AI-based tools can amplify impersonation or misleading content. Points out that significant investments in moderation efforts might still fail. | **Modified**: Refined focus on AI-driven manipulations and recognizes higher risks and costs associated with combatting them. |
| 8 | Other Digital Safety Abuses | Addresses the use of Microsoft consumer and enterprise services to generate or disseminate harmful or illegal content. Mentions potential regulatory demands and legal liability for failure to remove or moderate such content. | Maintains those concerns and cites expanding global regulatory oversight and conflicting legal frameworks. Notes possible civil or criminal liability if content moderation regulations are not met. | **Modified**: Strengthened discussion of increasing regulatory environment and stricter legal obligations around harmful content. |
| 9 | IoT and Execution Risks | Highlights risks related to the Internet of Things (IoT), where multiple hardware, software, or firmware layers outside Microsoft’s control may be vulnerable. Acknowledges possible massive data collection and personal safety issues. | Broadens the scope to all Microsoft products and services (including AI) to emphasize security, privacy, and execution risks. Stresses how customers’ own deployments, third-party interactions, and regulatory expectations compound these vulnerabilities. | **Modified**: Expanded from IoT-specific references to a broader view of how various products and services—especially AI—may be misused or cause harm, including personal safety issues. |
| 10 | Issues in the Development and Use of AI | Describes Microsoft’s AI investments and potential for flawed algorithms, biased datasets, harmful content, or ethical concerns. Warns that AI incidents could impair acceptance, cause harm to individuals, or lead to brand damage. | Continues to project AI usage and acknowledges growing regulatory scrutiny (e.g., EU AI Act). References new legal and IP claims linked to AI outputs. Broadens the potential for liability, reputational harm, and significant ethical consequences. | **Modified**: Sharpened focus on regulatory, legal, and ethical implications, including new and proposed AI-specific legislation, and the risk of unintended or potentially harmful AI use by customers or partners. |